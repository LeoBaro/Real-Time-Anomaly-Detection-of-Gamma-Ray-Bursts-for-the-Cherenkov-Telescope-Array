{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "appointed-fence",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/LeoBaro/phd/blob/main/rtapipe/analysis/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"tf.__version__: {tf.__version__}\")\n",
    "if tf.test.gpu_device_name(): \n",
    "    print(f\"Default GPU Device:{tf.test.gpu_device_name()}\")\n",
    "\n",
    "from os import getcwd\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-contest",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path(\"/home/baroncelli/phd/rtapipe/analysis/notebook_dataset_generation_for_models_output\")\n",
    "datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentdir = getcwd()\n",
    "currentdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-attempt",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outdir = Path(currentdir).joinpath(\"notebook_lstm_output\")\n",
    "outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-tulsa",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_url_root = \"https://raw.githubusercontent.com/numenta/NAB/master/data/\"\n",
    "\n",
    "df_small_noise_url_suffix = \"artificialNoAnomaly/art_daily_small_noise.csv\"\n",
    "df_small_noise_url = master_url_root + df_small_noise_url_suffix\n",
    "df_small_noise = pd.read_csv(\n",
    "    df_small_noise_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "df_daily_jumpsup_url_suffix = \"artificialWithAnomaly/art_daily_jumpsup.csv\"\n",
    "df_daily_jumpsup_url = master_url_root + df_daily_jumpsup_url_suffix\n",
    "df_daily_jumpsup = pd.read_csv(\n",
    "    df_daily_jumpsup_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_small_noise.head())\n",
    "\n",
    "print(df_daily_jumpsup.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_small_noise.plot(legend=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_daily_jumpsup.plot(legend=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mean = df_small_noise.mean()\n",
    "training_std = df_small_noise.std()\n",
    "df_training_value = (df_small_noise - training_mean) / training_std\n",
    "print(\"Number of training samples:\", len(df_training_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 288\n",
    "\n",
    "# Generated training sequences for use in the model.\n",
    "def create_sequences(values, time_steps=TIME_STEPS):\n",
    "    output = []\n",
    "    for i in range(len(values) - time_steps):\n",
    "        output.append(values[i : (i + time_steps)])\n",
    "    return np.stack(output)\n",
    "\n",
    "\n",
    "x_train = create_sequences(df_training_value.values)\n",
    "print(\"Training input shape: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-brook",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "modelConv = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(x_train.shape[1], x_train.shape[2])),\n",
    "        layers.Conv1D(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1D(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
    "    ]\n",
    ")\n",
    "modelConv.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "modelConv.summary()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-validity",
   "metadata": {},
   "source": [
    "## LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Input, Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLSTM = Sequential()\n",
    "modelLSTM.add(LSTM(16, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "modelLSTM.add(LSTM(8, activation='relu', return_sequences=False))\n",
    "modelLSTM.add(RepeatVector(x_train.shape[1]))\n",
    "modelLSTM.add(LSTM(8, activation='relu', return_sequences=True))\n",
    "modelLSTM.add(LSTM(16, activation='relu', return_sequences=True))\n",
    "modelLSTM.add(TimeDistributed(Dense(x_train.shape[2])))\n",
    "\n",
    "modelLSTM.compile(optimizer='adam', loss='mse')\n",
    "modelLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-screen",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelLSTM2 = Sequential()\n",
    "modelLSTM2.add(LSTM(32, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "modelLSTM2.add(Dropout(rate=0.3))\n",
    "modelLSTM2.add(RepeatVector(x_train.shape[1]))\n",
    "modelLSTM2.add(LSTM(32, return_sequences=True))\n",
    "modelLSTM2.add(Dropout(rate=0.3))\n",
    "modelLSTM2.add(TimeDistributed(Dense(x_train.shape[2])))\n",
    "\n",
    "modelLSTM2.compile(optimizer='adam', loss='mae')\n",
    "modelLSTM2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-sunglasses",
   "metadata": {},
   "source": [
    "## Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_lstm = Path(\"./training_lstm/cp.ckpt\")\n",
    "checkpoint_path_lstm.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "checkpoint_path_lstm2 = Path(\"./training_lstm2/cp.ckpt\")\n",
    "checkpoint_path_lstm2.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "checkpoint_path_conv = Path(\"./training_conv/cp.ckpt\")\n",
    "checkpoint_path_conv.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback_lstm  = keras.callbacks.ModelCheckpoint(filepath=str(checkpoint_path_lstm), save_weights_only=True, verbose=1)\n",
    "cp_callback_lstm2 = keras.callbacks.ModelCheckpoint(filepath=str(checkpoint_path_lstm2), save_weights_only=True, verbose=1)\n",
    "cp_callback_conv  = keras.callbacks.ModelCheckpoint(filepath=str(checkpoint_path_conv), save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-chocolate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#modelLSTM.load_weights(str(checkpoint_path_lstm))\n",
    "#modelLSTM2.load_weights(str(checkpoint_path_lstm2))\n",
    "#modelConv.load_weights(str(checkpoint_path_conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLSTMHistory = modelLSTM.fit(x_train, x_train, epochs=1, batch_size=128, validation_split=0.1, verbose=1, callbacks=[cp_callback_lstm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-nigeria",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelLSTM2History = modelLSTM2.fit(x_train, x_train, epochs=100, batch_size=128, validation_split=0.1, verbose=1, callbacks=[cp_callback_lstm2, keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-fusion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "modelConvHistory = modelConv.fit(x_train, x_train, epochs=50, batch_size=128, validation_split=0.1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\"),\n",
    "        cp_callback_conv\n",
    "    ],\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-campus",
   "metadata": {},
   "source": [
    "## Plotting the loss during the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(modelConvHistory.history[\"loss\"], label=\"CONV Training Loss\", color=\"grey\")\n",
    "#plt.plot(modelConvHistory.history[\"val_loss\"], label=\"CONV Validation Loss\", color=\"grey\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "plt.plot(modelLSTMHistory.history[\"loss\"], label=\"LSTM Training Loss\", color=\"orange\")\n",
    "plt.plot(modelLSTMHistory.history[\"val_loss\"], label=\"LSTM Validation Loss\", color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "plt.plot(modelLSTM2History.history[\"loss\"], label=\"LSTM2 Training Loss\", color=\"green\")\n",
    "plt.plot(modelLSTM2History.history[\"val_loss\"], label=\"LSTM2 Validation Loss\", color=\"green\", linestyle=\"--\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-packaging",
   "metadata": {},
   "source": [
    "## Plotting the loss distrubution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLoss(pred_data, real, labels=[\"\"]):\n",
    "    for i, pred in enumerate(pred_data):\n",
    "        train_mae_loss = np.mean(np.abs(pred - real), axis=1)\n",
    "        plt.hist(train_mae_loss, bins=50, label=labels[i])\n",
    "        plt.xlabel(\"Train MAE loss\")\n",
    "        plt.ylabel(\"No of samples\")\n",
    "        # Get reconstruction loss threshold.\n",
    "        threshold = np.max(train_mae_loss)\n",
    "        print(\"Reconstruction error threshold: \", threshold)    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder_predictions_on_training = modelConv.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions_on_training = modelLSTM.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm2_predictions_on_training = modelLSTM2.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(autoencoder_predictions_on_training.shape)\n",
    "print(lstm2_predictions_on_training.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLoss([lstm_predictions_on_training, lstm2_predictions_on_training], x_train, labels=[\"Lstm\",\"Lstm2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-sweet",
   "metadata": {},
   "source": [
    "## Plotting some reconstructed samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    plt.plot(x_train[i])\n",
    "    #plt.plot(autoencoder_predictions_on_training[0], label=\"Conv\")\n",
    "    plt.plot(lstm_predictions_on_training[1], label=\"Lstm\")\n",
    "    plt.plot(lstm2_predictions_on_training[1], label=\"Lstm\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
