{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "appointed-fence",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/LeoBaro/phd/blob/main/rtapipe/analysis/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confident-princess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-23 17:13:44.410731: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-03-23 17:13:44.410789: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "! python3 -c 'import tensorflow as tf; print(tf.__version__)'  # for Python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-aging",
   "metadata": {
    "id": "ceramic-celebrity"
   },
   "source": [
    "# Sequence-to-Sequence Prediction Problems\n",
    "Sequence prediction often involves forecasting the next value in a real valued sequence or outputting a class label for an input sequence.\n",
    "\n",
    "This is often framed as a sequence of one input time step to one output time step (e.g. one-to-one) or multiple input time steps to one output time step (many-to-one) type sequence prediction problem.\n",
    "\n",
    "One approach to seq2seq prediction problems that has proven very effective is called the Encoder-Decoder LSTM.\n",
    "\n",
    "## Encoder-Decoder LSTM \n",
    "The LSTM network can be organized into an architecture called the Encoder-Decoder LSTM that allows the model to be used to both support variable length input sequences and to predict or output variable length output sequences.\n",
    "\n",
    "In this architecture, an encoder LSTM model reads the input sequence step-by-step. After reading in the entire input sequence, the hidden state or output of this model represents an internal learned representation of the entire input sequence as a fixed-length vector. This vector is then provided as an input to the decoder model that interprets it as each step in the output sequence is generated\n",
    "This architecture is comprised of two models: one for reading the input sequence and encoding it into a fixed-length vector, and a second for decoding the fixed-length vector and outputting the predicted sequence. The use of the models in concert gives the architecture its name of Encoder-Decoder LSTM designed specifically for seq2seq problems.\n",
    "The innovation of this architecture is the use of a fixed-sized internal representation in the heart of the model that input sequences are read to and output sequences are read from. For this reason, the method may be referred to as sequence embedding.\n",
    "\n",
    "    … RNN Encoder-Decoder, consists of two recurrent neural networks (RNN) that act as an encoder and a decoder pair. The encoder maps a variable-length source sequence to a fixed-length vector, and the decoder maps the vector representation back to a variable-length target sequence.\n",
    "\n",
    "    — Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation, 2014.\n",
    "\n",
    "The Encoder-Decoder LSTM was developed for natural language processing problems where it demonstrated state-of-the-art performance, specifically in the area of text translation called statistical machine translation. \n",
    "\n",
    "    The proposed RNN Encoder-Decoder naturally generates a continuous-space representation of a phrase. […] From the visualization, it is clear that the RNN Encoder-Decoder captures both semantic and syntactic structures of the phrases\n",
    "\n",
    "    — Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation, 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-passion",
   "metadata": {
    "id": "moving-terrace"
   },
   "source": [
    "## Keras implementation\n",
    "\n",
    "For a given dataset of sequences, an encoder-decoder LSTM is configured to read the input sequence, encode it, decode it, and recreate it. The performance of the model is evaluated based on the model’s ability to recreate the input sequence.\n",
    "\n",
    "Once the model achieves a desired level of performance recreating the sequence, the decoder part of the model may be removed, leaving just the encoder model. This model can then be used to encode input sequences to a fixed-length vector.\n",
    "\n",
    "The resulting vectors can then be used in a variety of applications, not least as a compressed representation of the sequence as an input to another supervised learning model.\n",
    "\n",
    "We can think of the model as being comprised of two key parts: the encoder and the decoder.\n",
    "\n",
    "One or more LSTM layers can be used to implement the encoder model. The output of this model is a fixed-size vector that represents the internal representation of the input sequence. The number of memory cells in this layer defines the length of this fixed-sized vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-correction",
   "metadata": {
    "id": "k9IPBWWRAQFs"
   },
   "outputs": [],
   "source": [
    "from os import getcwd\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path(\"/data01/home/baroncelli/phd/repos/phd/rtapipe/analysis/notebook_dataset_generation_for_models_output\")\n",
    "datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentdir = getcwd()\n",
    "currentdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-attempt",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outdir = Path(currentdir).joinpath(\"notebook_lstm_output\")\n",
    "outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_url_root = \"https://raw.githubusercontent.com/numenta/NAB/master/data/\"\n",
    "\n",
    "df_small_noise_url_suffix = \"artificialNoAnomaly/art_daily_small_noise.csv\"\n",
    "df_small_noise_url = master_url_root + df_small_noise_url_suffix\n",
    "df_small_noise = pd.read_csv(\n",
    "    df_small_noise_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "df_daily_jumpsup_url_suffix = \"artificialWithAnomaly/art_daily_jumpsup.csv\"\n",
    "df_daily_jumpsup_url = master_url_root + df_daily_jumpsup_url_suffix\n",
    "df_daily_jumpsup = pd.read_csv(\n",
    "    df_daily_jumpsup_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_small_noise.head())\n",
    "\n",
    "print(df_daily_jumpsup.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_small_noise.plot(legend=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_daily_jumpsup.plot(legend=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mean = df_small_noise.mean()\n",
    "training_std = df_small_noise.std()\n",
    "df_training_value = (df_small_noise - training_mean) / training_std\n",
    "print(\"Number of training samples:\", len(df_training_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 288\n",
    "\n",
    "# Generated training sequences for use in the model.\n",
    "def create_sequences(values, time_steps=TIME_STEPS):\n",
    "    output = []\n",
    "    for i in range(len(values) - time_steps):\n",
    "        output.append(values[i : (i + time_steps)])\n",
    "    return np.stack(output)\n",
    "\n",
    "\n",
    "x_train = create_sequences(df_training_value.values)\n",
    "print(\"Training input shape: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-brook",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConv = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(x_train.shape[1], x_train.shape[2])),\n",
    "        layers.Conv1D(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1D(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
    "    ]\n",
    ")\n",
    "modelConv.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "modelConv.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-validity",
   "metadata": {},
   "source": [
    "## LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Input, Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLSTM = Sequential()\n",
    "modelLSTM.add(LSTM(64, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "modelLSTM.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "modelLSTM.add(RepeatVector(x_train.shape[1]))\n",
    "modelLSTM.add(LSTM(32, activation='relu', return_sequences=True))\n",
    "modelLSTM.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "modelLSTM.add(TimeDistributed(Dense(x_train.shape[2])))\n",
    "\n",
    "modelLSTM.compile(optimizer='adam', loss='mse')\n",
    "modelLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLSTM2 = Sequential()\n",
    "modelLSTM2.add(LSTM(128, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "modelLSTM2.add(Dropout(rate=0.2))\n",
    "modelLSTM2.add(RepeatVector(x_train.shape[1]))\n",
    "modelLSTM2.add(LSTM(128, return_sequences=True))\n",
    "modelLSTM2.add(Dropout(rate=0.2))\n",
    "modelLSTM2.add(TimeDistributed(Dense(x_train.shape[2])))\n",
    "\n",
    "modelLSTM2.compile(optimizer='adam', loss='mae')\n",
    "modelLSTM2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-sunglasses",
   "metadata": {},
   "source": [
    "## Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_lstm = Path(\"./training_lstm/cp.ckpt\")\n",
    "checkpoint_path_lstm.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "checkpoint_path_lstm2 = Path(\"./training_lstm2/cp.ckpt\")\n",
    "checkpoint_path_lstm2.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "checkpoint_path_conv = Path(\"./training_conv/cp.ckpt\")\n",
    "checkpoint_path_conv.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback_lstm = keras.callbacks.ModelCheckpoint(filepath=str(checkpoint_path_lstm), save_weights_only=True, verbose=1)\n",
    "cp_callback_lstm2 = keras.callbacks.ModelCheckpoint(filepath=str(checkpoint_path_lstm2), save_weights_only=True, verbose=1)\n",
    "cp_callback_conv = keras.callbacks.ModelCheckpoint(filepath=str(checkpoint_path_conv), save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-chocolate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelLSTM.load_weights(str(checkpoint_path_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLSTM2.load_weights(str(checkpoint_path_lstm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConv.load_weights(str(checkpoint_path_conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelLSTMHistory = modelLSTM.fit(x_train, x_train, epochs=2, batch_size=128, validation_split=0.1, verbose=1, callbacks=[cp_callback_lstm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-nigeria",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# modelLSTM2History = modelLSTM2.fit(x_train, x_train, epochs=epochs, batch_size=128, validation_split=0.1, verbose=1, callbacks=[cp_callback_lstm2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-fusion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelConvHistory = modelConv.fit(x_train, x_train, epochs=50, batch_size=128, validation_split=0.1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\"),\n",
    "        cp_callback_conv\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(modelConvHistory.history[\"loss\"], label=\"CONV Training Loss\", color=\"grey\")\n",
    "plt.plot(modelConvHistory.history[\"val_loss\"], label=\"CONV Validation Loss\", color=\"grey\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "plt.plot(modelLSTMHistory.history[\"loss\"], label=\"LSTM Training Loss\", color=\"orange\")\n",
    "plt.plot(modelLSTMHistory.history[\"val_loss\"], label=\"LSTM Validation Loss\", color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "plt.plot(modelLSTM2History.history[\"loss\"], label=\"LSTM2 Training Loss\", color=\"green\")\n",
    "plt.plot(modelLSTM2History.history[\"val_loss\"], label=\"LSTM2 Validation Loss\", color=\"green\", linestyle=\"--\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-packaging",
   "metadata": {},
   "source": [
    "## Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLoss(pred_data, real, labels=[\"\"]):\n",
    "    for i, pred in enumerate(pred_data):\n",
    "        train_mae_loss = np.mean(np.abs(pred - real), axis=1)\n",
    "        plt.hist(train_mae_loss, bins=50, label=labels[i])\n",
    "        plt.xlabel(\"Train MAE loss\")\n",
    "        plt.ylabel(\"No of samples\")\n",
    "        # Get reconstruction loss threshold.\n",
    "        threshold = np.max(train_mae_loss)\n",
    "        print(\"Reconstruction error threshold: \", threshold)    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_predictions_on_training = modelConv.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions_on_training = modelLSTM.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm2_predictions_on_training = modelLSTM2.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(autoencoder_predictions_on_training.shape)\n",
    "print(lstm2_predictions_on_training.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLoss([autoencoder_predictions_on_training, lstm_predictions_on_training, lstm2_predictions_on_training], x_train, labels=[\"Conv\",\"Lstm\",\"Lstm2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train[0])\n",
    "plt.plot(autoencoder_predictions_on_training[0], label=\"Conv\")\n",
    "plt.plot(lstm_predictions_on_training[0], label=\"Lstm\")\n",
    "plt.plot(lstm2_predictions_on_training[0], label=\"Lstm\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-international",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-tablet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-writing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-death",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train MAE loss.\n",
    "x_train_pred = model.predict(x_train)\n",
    "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)\n",
    "\n",
    "plt.hist(train_mae_loss, bins=50)\n",
    "plt.xlabel(\"Train MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n",
    "# Get reconstruction loss threshold.\n",
    "threshold = np.max(train_mae_loss)\n",
    "print(\"Reconstruction error threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train[0])\n",
    "plt.plot(x_train_pred[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-transsexual",
   "metadata": {
    "id": "diverse-roulette"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.LSTM(50, activation='relu', input_shape=(n_in,1)))\n",
    "model.add(layers.RepeatVector(n_in))\n",
    "model.add(layers.LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
